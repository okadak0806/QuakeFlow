{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e545fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f2d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法3: split_hypodd関数を実行してindexを取得\n",
    "def get_index_from_split_hypodd(\n",
    "    config_json: str = \"config/config.json\",\n",
    "    catalog_csv: str = \"gamma/gamma_catalog.csv\"\n",
    ") -> list:\n",
    "    \"\"\"split_hypodd関数を実行してindex範囲を取得\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    try:\n",
    "        with open(config_json, \"r\") as fp:\n",
    "            config = json.load(fp)\n",
    "\n",
    "        events = pd.read_csv(catalog_csv)\n",
    "\n",
    "        if \"MAXEVENT\" in config[\"hypodd\"]:\n",
    "            MAXEVENT = config[\"hypodd\"][\"MAXEVENT\"]\n",
    "        else:\n",
    "            MAXEVENT = 1e4\n",
    "\n",
    "        MAXEVENT = len(events) // ((len(events) - 1) // MAXEVENT + 1) + 1\n",
    "        num_parallel = int((len(events) - 1) // MAXEVENT + 1)\n",
    "        \n",
    "        index_list = list(range(num_parallel))\n",
    "        print(f\"Calculated index from catalog: {index_list} (total events: {len(events)}, MAXEVENT: {MAXEVENT})\")\n",
    "        return index_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating index: {e}\")\n",
    "        print(\"Using default index [0]\")\n",
    "        return [0]\n",
    "\n",
    "# カタログから動的にindexを計算\n",
    "index = get_index_from_split_hypodd()\n",
    "print(f\"Calculated index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hypodd(\n",
    "    index: list,\n",
    "    config_json: \"json\",\n",
    "    catalog_ct: str,\n",
    "    catalog_cc: str,\n",
    "    # bucket_name: str = \"catalogs\",\n",
    "    # s3_url: str = \"minio-service:9000\",\n",
    "    # secure: bool = False,\n",
    "):\n",
    "    import json\n",
    "    import os\n",
    "    from glob import glob\n",
    "\n",
    "    # from minio import Minio\n",
    "\n",
    "    # minioClient = Minio(s3_url, access_key=\"minio\", secret_key=\"minio123\", secure=secure)\n",
    "\n",
    "    with open(config_json, \"r\") as fp:\n",
    "        config = json.load(fp)\n",
    "\n",
    "    # objects = minioClient.list_objects(bucket_name, prefix=f\"{config['region']}/hypodd/hypodd_\", recursive=True)\n",
    "\n",
    "    # Extract hypo_reloc archive if it exists\n",
    "    hypo_reloc_dir = \"hypo_reloc\"\n",
    "    archive_path = \"hypo_reloc.tar.gz\"\n",
    "    \n",
    "    if os.path.exists(archive_path):\n",
    "        print(f\"Found archive: {archive_path}, extracting...\")\n",
    "        import tarfile\n",
    "        with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "            tar.extractall()\n",
    "        print(f\"Archive extracted successfully\")\n",
    "        \n",
    "    if os.path.exists(hypo_reloc_dir):\n",
    "        print(f\"Using files from extracted directory: {hypo_reloc_dir}\")\n",
    "        hypodd_ct_catalogs = [os.path.join(hypo_reloc_dir, f\"hypodd_ct_{i:03d}.reloc\") for i in index]\n",
    "        hypodd_cc_catalogs = [os.path.join(hypo_reloc_dir, f\"hypodd_cc_{i:03d}.reloc\") for i in index]\n",
    "    else:\n",
    "        # Fallback to legacy hy/ directory structure\n",
    "        print(\"No hypo_reloc directory found, using legacy hy/ structure\")\n",
    "        tmp_path = lambda x: os.path.join(\"hy/\", x)\n",
    "        hypodd_ct_catalogs = [tmp_path(f\"hypodd_ct_{i:03d}.reloc\") for i in index]\n",
    "        hypodd_cc_catalogs = [tmp_path(f\"hypodd_cc_{i:03d}.reloc\") for i in index]\n",
    "    # Create output directory\n",
    "    output_dir = \"merged_outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Merge CT catalogs\n",
    "    print(f\"Merging CT catalogs: {hypodd_ct_catalogs}\")\n",
    "    ct_temp_file = os.path.join(output_dir, 'hypodd_ct_catalog_temp.txt')\n",
    "    \n",
    "    # Check which files exist\n",
    "    existing_ct_files = [f for f in hypodd_ct_catalogs if os.path.exists(f)]\n",
    "    if existing_ct_files:\n",
    "        print(f\"Found CT files: {existing_ct_files}\")\n",
    "        os.system(f\"cat {' '.join(existing_ct_files)} > {ct_temp_file}\")\n",
    "        os.system(f\"cat {ct_temp_file} > {catalog_ct}\")\n",
    "    else:\n",
    "        print(\"No CT files found, creating empty catalog\")\n",
    "        with open(catalog_ct, 'w') as f:\n",
    "            f.write(\"# No CT relocation files found\\n\")\n",
    "\n",
    "    # Merge CC catalogs  \n",
    "    print(f\"Merging CC catalogs: {hypodd_cc_catalogs}\")\n",
    "    cc_temp_file = os.path.join(output_dir, 'hypodd_cc_catalog_temp.txt')\n",
    "    \n",
    "    # Check which files exist and are not empty\n",
    "    existing_cc_files = []\n",
    "    for f in hypodd_cc_catalogs:\n",
    "        if os.path.exists(f) and os.path.getsize(f) > 50:  # Skip empty placeholder files\n",
    "            existing_cc_files.append(f)\n",
    "    \n",
    "    if existing_cc_files:\n",
    "        print(f\"Found CC files: {existing_cc_files}\")\n",
    "        os.system(f\"cat {' '.join(existing_cc_files)} > {cc_temp_file}\")\n",
    "        os.system(f\"cat {cc_temp_file} > {catalog_cc}\")\n",
    "    else:\n",
    "        print(\"No CC files found or all files are empty, creating empty catalog\")\n",
    "        with open(catalog_cc, 'w') as f:\n",
    "            f.write(\"# No CC relocation files found\\n\")\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a918413",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_hypodd(\n",
    "    index=get_index_from_split_hypodd(),\n",
    "    config_json=\"config/config.json\",\n",
    "    catalog_ct=\"hypodd_ct_catalog.txt\",\n",
    "    catalog_cc=\"hypodd_cc_catalog.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f2fcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T02:33:27.435238Z",
     "iopub.status.busy": "2025-06-03T02:33:27.434883Z",
     "iopub.status.idle": "2025-06-03T02:33:27.438600Z",
     "shell.execute_reply": "2025-06-03T02:33:27.437997Z"
    },
    "papermill": {
     "duration": 0.006845,
     "end_time": "2025-06-03T02:33:27.439654",
     "exception": false,
     "start_time": "2025-06-03T02:33:27.432809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kubeflow Pipelines UI用のメタデータ出力\n",
    "if os.environ.get('ELYRA_RUNTIME_ENV') == 'kfp':\n",
    "    # For information about Elyra environment variables refer to\n",
    "    # https://elyra.readthedocs.io/en/stable/user_guide/best-practices-file-based-nodes.html#proprietary-environment-variables\n",
    "\n",
    "    metadata = {\n",
    "        'outputs': [\n",
    "            {\n",
    "                'storage': 'inline',\n",
    "                'source': f'# Merge hypodd results Complete\\n...',\n",
    "                'type': 'markdown',\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open('mlpipeline-ui-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.969604,
   "end_time": "2025-06-03T02:33:27.556863",
   "environment_variables": {},
   "exception": null,
   "input_path": "Set_Config.ipynb",
   "output_path": "Set_Config-output.ipynb",
   "parameters": {},
   "start_time": "2025-06-03T02:33:26.587259",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
