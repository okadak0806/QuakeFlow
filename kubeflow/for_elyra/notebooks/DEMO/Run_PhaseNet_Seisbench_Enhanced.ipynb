{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Enhanced PhaseNet with SeisBench PyTorch Integration\n",
    "\n",
    "**Advanced earthquake phase picking using SeisBench PyTorch models**\n",
    "\n",
    "This notebook implements PhaseNet phase picking using SeisBench's PyTorch-based models, specifically optimized for Japanese earthquake data processing with GPU acceleration and fine-tuning capabilities.\n",
    "\n",
    "## Features\n",
    "- PyTorch-based PhaseNet models from SeisBench\n",
    "- GPU acceleration for batch processing\n",
    "- Japanese earthquake data optimization\n",
    "- Advanced preprocessing and data augmentation\n",
    "- Model fine-tuning capabilities\n",
    "- Comprehensive quality metrics\n",
    "\n",
    "## Inputs\n",
    "- Waveform data (waveforms.tar.gz)\n",
    "- Station metadata (stations/stations.json)\n",
    "- Processing configuration (config/config.json)\n",
    "\n",
    "## Outputs\n",
    "- Phase picks (phasenet_seisbench/picks_seisbench.csv)\n",
    "- Processing summary (phasenet_seisbench/processing_summary.json)\n",
    "- Quality metrics (phasenet_seisbench/quality_metrics.png)\n",
    "- Model diagnostics (phasenet_seisbench/model_diagnostics.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch and SeisBench imports\n",
    "import torch\n",
    "import seisbench\n",
    "import seisbench.models as sbm\n",
    "\n",
    "# ObsPy for seismic data\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "# Add common utilities to path\n",
    "sys.path.append('/app/examples')\n",
    "from common import (\n",
    "    notebook_setup, notebook_finalize, \n",
    "    RegionConfig, DataIO,\n",
    "    SeisbenchPhaseNetProcessor\n",
    ")\n",
    "\n",
    "print(f\"ðŸ§  SeisBench Enhanced PhaseNet Processor - Starting...\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"   SeisBench version: {seisbench.__version__}\")\n",
    "print(f\"   Notebook start time: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Elyra environment and configuration\n",
    "start_time = datetime.now()\n",
    "config, region_name, elyra_env = notebook_setup(\n",
    "    default_region=\"japan\",\n",
    "    required_inputs=[\n",
    "        \"waveforms.tar.gz\",\n",
    "        \"fname.csv\", \n",
    "        \"stations/stations.json\",\n",
    "        \"config/config.json\"\n",
    "    ],\n",
    "    outputs_dir=\"phasenet_seisbench\"\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“‹ Enhanced PhaseNet SeisBench Configuration:\")\n",
    "print(f\"   Region: {region_name}\")\n",
    "print(f\"   Device preference: {config.config.get('processing', {}).get('phasenet', {}).get('device', 'auto')}\")\n",
    "print(f\"   Model type: {config.config.get('processing', {}).get('phasenet', {}).get('model', 'phasenet')}\")\n",
    "print(f\"   Batch size: {config.config.get('processing', {}).get('phasenet', {}).get('batch_size', 32)}\")\n",
    "print(f\"   Japan-specific: {config.config.get('processing', {}).get('phasenet', {}).get('japan_specific', False)}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"phasenet_seisbench\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"ðŸ“ Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize SeisBench PhaseNet processor\n",
    "print(f\"ðŸš€ Initializing SeisBench PhaseNet processor...\")\n",
    "\n",
    "try:\n",
    "    processor = SeisbenchPhaseNetProcessor(\n",
    "        config=config,\n",
    "        protocol=\"file\",\n",
    "        root_path=\"./\"\n",
    "    )\n",
    "    print(f\"âœ… Processor initialized successfully\")\n",
    "    \n",
    "    # Load the model\n",
    "    print(f\"ðŸ”„ Loading SeisBench PhaseNet model...\")\n",
    "    processor.load_model(pretrained=True)\n",
    "    print(f\"âœ… Model loaded successfully\")\n",
    "    \n",
    "    # Display model information\n",
    "    print(f\"\\nðŸ“Š Model Information:\")\n",
    "    print(f\"   Model type: {type(processor.model).__name__}\")\n",
    "    print(f\"   Device: {processor.device}\")\n",
    "    print(f\"   Parameters: {sum(p.numel() for p in processor.model.parameters()):,}\")\n",
    "    print(f\"   Trainable parameters: {sum(p.numel() for p in processor.model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error initializing processor: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and extract waveform data\n",
    "print(f\"ðŸ“¦ Loading waveform data...\")\n",
    "\n",
    "# Extract waveforms archive if needed\n",
    "if os.path.exists(\"waveforms.tar.gz\") and not os.path.exists(\"waveforms\"):\n",
    "    print(f\"   Extracting waveforms.tar.gz...\")\n",
    "    import tarfile\n",
    "    with tarfile.open(\"waveforms.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\".\")\n",
    "    print(f\"   âœ… Waveforms extracted\")\n",
    "\n",
    "# Load waveform directory path from fname.csv if available\n",
    "waveform_dir = \"waveforms\"\n",
    "if os.path.exists(\"fname.csv\"):\n",
    "    fname_df = pd.read_csv(\"fname.csv\")\n",
    "    if 'waveform_dir' in fname_df.columns and len(fname_df) > 0:\n",
    "        waveform_dir = fname_df['waveform_dir'].iloc[0]\n",
    "    print(f\"   Waveform directory from fname.csv: {waveform_dir}\")\n",
    "\n",
    "# Verify waveform directory exists\n",
    "if not os.path.exists(waveform_dir):\n",
    "    print(f\"âš ï¸ Waveform directory not found: {waveform_dir}\")\n",
    "    # Try alternative paths\n",
    "    alternative_paths = [\"./waveforms\", \"../waveforms\", \".\"]\n",
    "    for alt_path in alternative_paths:\n",
    "        if os.path.exists(alt_path) and any(Path(alt_path).glob(\"**/*.[sm]*\")):\n",
    "            waveform_dir = alt_path\n",
    "            print(f\"   Using alternative path: {waveform_dir}\")\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No waveform data found in expected locations\")\n",
    "\n",
    "print(f\"ðŸ“Š Waveform data location: {waveform_dir}\")\n",
    "\n",
    "# Count available waveform files\n",
    "waveform_files = list(Path(waveform_dir).glob(\"**/*.[sm]*\"))\n",
    "print(f\"   Found {len(waveform_files)} waveform files\")\n",
    "\n",
    "if len(waveform_files) == 0:\n",
    "    print(f\"âš ï¸ No waveform files found with expected extensions (.mseed, .sac, .seed)\")\n",
    "    # Show available files for debugging\n",
    "    all_files = list(Path(waveform_dir).glob(\"**/*\"))[:10]\n",
    "    print(f\"   Sample files in directory: {[f.name for f in all_files]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process waveforms with SeisBench PhaseNet\n",
    "print(f\"ðŸŒŠ Processing waveforms with SeisBench PhaseNet...\")\n",
    "\n",
    "processing_start = datetime.now()\n",
    "\n",
    "try:\n",
    "    # Run the processing\n",
    "    picks_df = processor.process_waveforms(\n",
    "        waveform_dir=waveform_dir,\n",
    "        stations_file=\"stations/stations.json\",\n",
    "        output_dir=output_dir,\n",
    "        start_time=config.config.get('time_range', {}).get('starttime'),\n",
    "        end_time=config.config.get('time_range', {}).get('endtime')\n",
    "    )\n",
    "    \n",
    "    processing_end = datetime.now()\n",
    "    processing_time = (processing_end - processing_start).total_seconds()\n",
    "    \n",
    "    print(f\"âœ… Processing completed in {processing_time:.1f} seconds\")\n",
    "    print(f\"ðŸ“Š Results Summary:\")\n",
    "    print(f\"   Total picks: {len(picks_df)}\")\n",
    "    \n",
    "    if len(picks_df) > 0:\n",
    "        p_picks = len(picks_df[picks_df['phase'] == 'P'])\n",
    "        s_picks = len(picks_df[picks_df['phase'] == 'S'])\n",
    "        unique_stations = picks_df['station'].nunique()\n",
    "        \n",
    "        print(f\"   P-wave picks: {p_picks}\")\n",
    "        print(f\"   S-wave picks: {s_picks}\")\n",
    "        print(f\"   Unique stations: {unique_stations}\")\n",
    "        print(f\"   Processing rate: {len(picks_df)/processing_time:.1f} picks/second\")\n",
    "        \n",
    "        # Display sample picks\n",
    "        print(f\"\\nðŸ“‹ Sample picks:\")\n",
    "        display(picks_df.head(10))\n",
    "    else:\n",
    "        print(f\"âš ï¸ No picks detected - check thresholds and data quality\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during processing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate quality metrics and visualizations\n",
    "if len(picks_df) > 0:\n",
    "    print(f\"ðŸ“Š Generating quality metrics and visualizations...\")\n",
    "    \n",
    "    # Create comprehensive quality analysis\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('SeisBench PhaseNet Quality Metrics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Pick distribution by phase\n",
    "    phase_counts = picks_df['phase'].value_counts()\n",
    "    axes[0, 0].pie(phase_counts.values, labels=phase_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Pick Distribution by Phase')\n",
    "    \n",
    "    # 2. Probability distribution\n",
    "    axes[0, 1].hist(picks_df['probability'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].axvline(picks_df['probability'].mean(), color='red', linestyle='--', label=f'Mean: {picks_df[\"probability\"].mean():.3f}')\n",
    "    axes[0, 1].set_xlabel('Pick Probability')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].set_title('Pick Probability Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Picks per station\n",
    "    station_counts = picks_df['station'].value_counts().head(15)\n",
    "    axes[0, 2].barh(range(len(station_counts)), station_counts.values)\n",
    "    axes[0, 2].set_yticks(range(len(station_counts)))\n",
    "    axes[0, 2].set_yticklabels(station_counts.index, fontsize=8)\n",
    "    axes[0, 2].set_xlabel('Number of Picks')\n",
    "    axes[0, 2].set_title('Top 15 Stations by Pick Count')\n",
    "    \n",
    "    # 4. Temporal distribution\n",
    "    picks_df['datetime'] = pd.to_datetime(picks_df['time'])\n",
    "    picks_df['hour'] = picks_df['datetime'].dt.hour\n",
    "    hourly_picks = picks_df['hour'].value_counts().sort_index()\n",
    "    axes[1, 0].plot(hourly_picks.index, hourly_picks.values, marker='o')\n",
    "    axes[1, 0].set_xlabel('Hour of Day')\n",
    "    axes[1, 0].set_ylabel('Number of Picks')\n",
    "    axes[1, 0].set_title('Temporal Distribution of Picks')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Phase probability comparison\n",
    "    p_probs = picks_df[picks_df['phase'] == 'P']['probability']\n",
    "    s_probs = picks_df[picks_df['phase'] == 'S']['probability']\n",
    "    \n",
    "    axes[1, 1].hist(p_probs, bins=20, alpha=0.7, label='P-wave', color='blue')\n",
    "    axes[1, 1].hist(s_probs, bins=20, alpha=0.7, label='S-wave', color='red')\n",
    "    axes[1, 1].set_xlabel('Probability')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Phase Probability Comparison')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # 6. Quality metrics summary\n",
    "    metrics_text = f\"\"\"\n",
    "PROCESSING SUMMARY\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Total Picks: {len(picks_df):,}\n",
    "P-wave Picks: {len(p_probs):,}\n",
    "S-wave Picks: {len(s_probs):,}\n",
    "Unique Stations: {picks_df['station'].nunique()}\n",
    "Processing Time: {processing_time:.1f}s\n",
    "Rate: {len(picks_df)/processing_time:.1f} picks/s\n",
    "\n",
    "QUALITY METRICS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Mean Probability: {picks_df['probability'].mean():.3f}\n",
    "Std Probability: {picks_df['probability'].std():.3f}\n",
    "High Quality (>0.8): {len(picks_df[picks_df['probability'] > 0.8])}\n",
    "Medium Quality (0.5-0.8): {len(picks_df[(picks_df['probability'] >= 0.5) & (picks_df['probability'] <= 0.8)])}\n",
    "Low Quality (<0.5): {len(picks_df[picks_df['probability'] < 0.5])}\n",
    "\n",
    "DEVICE INFO\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Device: {processor.device}\n",
    "Model: {processor.model_name}\n",
    "Batch Size: {processor.batch_size}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[1, 2].text(0.05, 0.95, metrics_text, transform=axes[1, 2].transAxes, \n",
    "                   fontsize=9, verticalalignment='top', fontfamily='monospace')\n",
    "    axes[1, 2].set_xlim(0, 1)\n",
    "    axes[1, 2].set_ylim(0, 1)\n",
    "    axes[1, 2].axis('off')\n",
    "    axes[1, 2].set_title('Processing Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    quality_metrics_path = os.path.join(output_dir, 'quality_metrics.png')\n",
    "    plt.savefig(quality_metrics_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ðŸ’¾ Quality metrics saved: {quality_metrics_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âš ï¸ Skipping quality metrics - no picks detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate model diagnostics and performance metrics\n",
    "print(f\"ðŸ” Generating model diagnostics...\")\n",
    "\n",
    "try:\n",
    "    # Collect model diagnostics\n",
    "    model_diagnostics = {\n",
    "        \"model_info\": {\n",
    "            \"model_name\": processor.model_name,\n",
    "            \"model_type\": type(processor.model).__name__,\n",
    "            \"total_parameters\": sum(p.numel() for p in processor.model.parameters()),\n",
    "            \"trainable_parameters\": sum(p.numel() for p in processor.model.parameters() if p.requires_grad),\n",
    "            \"device\": str(processor.device),\n",
    "            \"seisbench_version\": seisbench.__version__,\n",
    "            \"pytorch_version\": torch.__version__\n",
    "        },\n",
    "        \"processing_config\": {\n",
    "            \"batch_size\": processor.batch_size,\n",
    "            \"sampling_rate\": processor.sampling_rate,\n",
    "            \"window_length_sec\": processor.window_length_sec,\n",
    "            \"overlap_sec\": processor.overlap_sec,\n",
    "            \"threshold_p\": processor.threshold_p,\n",
    "            \"threshold_s\": processor.threshold_s,\n",
    "            \"japan_specific\": processor.japan_specific\n",
    "        },\n",
    "        \"performance_metrics\": {\n",
    "            \"processing_time_seconds\": processing_time,\n",
    "            \"total_picks\": len(picks_df),\n",
    "            \"picks_per_second\": len(picks_df) / processing_time if processing_time > 0 else 0,\n",
    "            \"total_windows_processed\": len(processor.window_metadata) if hasattr(processor, 'window_metadata') else 0\n",
    "        },\n",
    "        \"quality_metrics\": {\n",
    "            \"mean_probability\": float(picks_df['probability'].mean()) if len(picks_df) > 0 else 0,\n",
    "            \"std_probability\": float(picks_df['probability'].std()) if len(picks_df) > 0 else 0,\n",
    "            \"high_quality_picks\": int(len(picks_df[picks_df['probability'] > 0.8])) if len(picks_df) > 0 else 0,\n",
    "            \"medium_quality_picks\": int(len(picks_df[(picks_df['probability'] >= 0.5) & (picks_df['probability'] <= 0.8)])) if len(picks_df) > 0 else 0,\n",
    "            \"low_quality_picks\": int(len(picks_df[picks_df['probability'] < 0.5])) if len(picks_df) > 0 else 0\n",
    "        },\n",
    "        \"system_info\": {\n",
    "            \"cuda_available\": torch.cuda.is_available(),\n",
    "            \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "            \"gpu_memory_gb\": torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else None,\n",
    "            \"processing_timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save model diagnostics\n",
    "    diagnostics_path = os.path.join(output_dir, 'model_diagnostics.json')\n",
    "    with open(diagnostics_path, 'w') as f:\n",
    "        json.dump(model_diagnostics, f, indent=2)\n",
    "    \n",
    "    print(f\"ðŸ’¾ Model diagnostics saved: {diagnostics_path}\")\n",
    "    print(f\"\\nðŸ“Š Model Diagnostics Summary:\")\n",
    "    print(f\"   Model: {model_diagnostics['model_info']['model_name']}\")\n",
    "    print(f\"   Parameters: {model_diagnostics['model_info']['total_parameters']:,}\")\n",
    "    print(f\"   Device: {model_diagnostics['model_info']['device']}\")\n",
    "    print(f\"   Processing rate: {model_diagnostics['performance_metrics']['picks_per_second']:.1f} picks/sec\")\n",
    "    \n",
    "    if len(picks_df) > 0:\n",
    "        print(f\"   Quality distribution:\")\n",
    "        print(f\"     High (>0.8): {model_diagnostics['quality_metrics']['high_quality_picks']}\")\n",
    "        print(f\"     Medium (0.5-0.8): {model_diagnostics['quality_metrics']['medium_quality_picks']}\")\n",
    "        print(f\"     Low (<0.5): {model_diagnostics['quality_metrics']['low_quality_picks']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error generating diagnostics: {e}\")\n",
    "    model_diagnostics = {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finalize processing and generate comprehensive summary\n",
    "print(f\"ðŸ“‹ Finalizing SeisBench PhaseNet processing...\")\n",
    "\n",
    "# Create final processing summary\n",
    "final_summary = {\n",
    "    \"notebook_info\": {\n",
    "        \"name\": \"Run_PhaseNet_Seisbench_Enhanced\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"description\": \"Enhanced PhaseNet with SeisBench PyTorch integration\",\n",
    "        \"start_time\": start_time.isoformat(),\n",
    "        \"end_time\": datetime.now().isoformat(),\n",
    "        \"total_runtime_seconds\": (datetime.now() - start_time).total_seconds()\n",
    "    },\n",
    "    \"input_data\": {\n",
    "        \"waveform_dir\": waveform_dir,\n",
    "        \"waveform_files_found\": len(waveform_files),\n",
    "        \"stations_file\": \"stations/stations.json\",\n",
    "        \"config_file\": \"config/config.json\",\n",
    "        \"region\": region_name\n",
    "    },\n",
    "    \"processing_results\": {\n",
    "        \"total_picks\": len(picks_df),\n",
    "        \"p_picks\": len(picks_df[picks_df['phase'] == 'P']) if len(picks_df) > 0 else 0,\n",
    "        \"s_picks\": len(picks_df[picks_df['phase'] == 'S']) if len(picks_df) > 0 else 0,\n",
    "        \"unique_stations\": picks_df['station'].nunique() if len(picks_df) > 0 else 0,\n",
    "        \"processing_time_seconds\": processing_time,\n",
    "        \"success\": len(picks_df) > 0\n",
    "    },\n",
    "    \"output_files\": {\n",
    "        \"picks_csv\": f\"{output_dir}/picks_seisbench.csv\",\n",
    "        \"processing_summary\": f\"{output_dir}/processing_summary.json\",\n",
    "        \"quality_metrics\": f\"{output_dir}/quality_metrics.png\",\n",
    "        \"model_diagnostics\": f\"{output_dir}/model_diagnostics.json\"\n",
    "    },\n",
    "    \"model_info\": model_diagnostics.get('model_info', {}),\n",
    "    \"system_info\": model_diagnostics.get('system_info', {})\n",
    "}\n",
    "\n",
    "# Save final summary\n",
    "final_summary_path = os.path.join(output_dir, 'final_summary.json')\n",
    "with open(final_summary_path, 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2)\n",
    "\n",
    "print(f\"ðŸ’¾ Final summary saved: {final_summary_path}\")\n",
    "\n",
    "# Call notebook finalization\n",
    "notebook_finalize(\n",
    "    config=config,\n",
    "    success=len(picks_df) > 0,\n",
    "    output_files=[\n",
    "        f\"{output_dir}/picks_seisbench.csv\",\n",
    "        f\"{output_dir}/processing_summary.json\",\n",
    "        f\"{output_dir}/quality_metrics.png\",\n",
    "        f\"{output_dir}/model_diagnostics.json\",\n",
    "        f\"{output_dir}/final_summary.json\"\n",
    "    ],\n",
    "    summary=final_summary\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ SeisBench PhaseNet Enhanced Processing Complete!\")\n",
    "print(f\"   Runtime: {(datetime.now() - start_time).total_seconds():.1f} seconds\")\n",
    "print(f\"   Picks detected: {len(picks_df)}\")\n",
    "print(f\"   Success: {'âœ… Yes' if len(picks_df) > 0 else 'âŒ No picks detected'}\")\n",
    "print(f\"   Output directory: {output_dir}\")\n",
    "\n",
    "if len(picks_df) > 0:\n",
    "    print(f\"\\nðŸ“ˆ Key Performance Indicators:\")\n",
    "    print(f\"   Processing efficiency: {len(picks_df)/processing_time:.1f} picks/second\")\n",
    "    print(f\"   Average pick confidence: {picks_df['probability'].mean():.3f}\")\n",
    "    print(f\"   High-quality picks (>0.8): {len(picks_df[picks_df['probability'] > 0.8])}\")\n",
    "    print(f\"   Station coverage: {picks_df['station'].nunique()} stations\")\n",
    "else:\n",
    "    print(f\"\\nðŸ”§ Troubleshooting suggestions:\")\n",
    "    print(f\"   â€¢ Check detection thresholds (P: {processor.threshold_p}, S: {processor.threshold_s})\")\n",
    "    print(f\"   â€¢ Verify waveform data quality and format\")\n",
    "    print(f\"   â€¢ Consider adjusting preprocessing parameters\")\n",
    "    print(f\"   â€¢ Review station metadata compatibility\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",\n",
   "language": "python",\n",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",\    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}