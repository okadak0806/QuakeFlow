{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Enhanced Configuration Setup for QuakeFlow Pipeline\n",
    "\n",
    "This notebook sets up configuration for earthquake data processing using the unified QuakeFlow framework.\n",
    "It leverages the common utilities and standardized configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common utilities\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add common utilities to path\n",
    "examples_dir = Path.cwd().parent.parent / 'examples'\n",
    "if str(examples_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(examples_dir))\n",
    "\n",
    "# Import QuakeFlow common utilities\n",
    "from common import notebook_setup, notebook_finalize, ElyraUtils, RegionConfig\n",
    "\n",
    "print(\"QuakeFlow common utilities imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration using unified framework\n",
    "region_config, workflow, parallel_config = notebook_setup()\n",
    "\n",
    "region_name = region_config.region\n",
    "num_parallel = parallel_config['num_parallel']\n",
    "\n",
    "print(f\"Region: {region_name}\")\n",
    "print(f\"Parallel processes: {num_parallel}\")\n",
    "print(f\"Configuration loaded: {region_config.config is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geographic bounds and time range from unified config\n",
    "bounds = region_config.get_geographic_bounds()\n",
    "processing_config = region_config.get_processing_config('phasenet')\n",
    "\n",
    "# Extract configuration with defaults\n",
    "center = (\n",
    "    (bounds['minlongitude'] + bounds['maxlongitude']) / 2,\n",
    "    (bounds['minlatitude'] + bounds['maxlatitude']) / 2\n",
    ")\n",
    "\n",
    "# Get time range from environment or use defaults\n",
    "import obspy\n",
    "import datetime\n",
    "\n",
    "# Time range configuration\n",
    "start_time_str = os.environ.get('START_TIME')\n",
    "end_time_str = os.environ.get('END_TIME')\n",
    "\n",
    "if start_time_str and end_time_str:\n",
    "    starttime = obspy.UTCDateTime(start_time_str)\n",
    "    endtime = obspy.UTCDateTime(end_time_str)\n",
    "else:\n",
    "    # Use region-specific defaults\n",
    "    if region_name.lower() == \"demo\":\n",
    "        starttime = obspy.UTCDateTime(\"2019-07-04T17\")\n",
    "        endtime = obspy.UTCDateTime(\"2019-07-04T19\")\n",
    "    elif region_name.lower() == \"california\":\n",
    "        starttime = obspy.UTCDateTime(\"2019-07-04T00\")\n",
    "        endtime = obspy.UTCDateTime(\"2019-07-10T00\")\n",
    "    elif region_name.lower() == \"japan\":\n",
    "        starttime = obspy.UTCDateTime(\"2024-01-01T00\")\n",
    "        endtime = obspy.UTCDateTime(\"2024-01-31T00\")\n",
    "    elif region_name.lower() == \"hawaii\":\n",
    "        starttime = obspy.UTCDateTime(\"2018-01-01T00\")\n",
    "        endtime = obspy.UTCDateTime(\"2022-08-12T00\")\n",
    "    else:\n",
    "        # Default to demo settings\n",
    "        starttime = obspy.UTCDateTime(\"2019-07-04T17\")\n",
    "        endtime = obspy.UTCDateTime(\"2019-07-04T19\")\n",
    "\n",
    "print(f\"Center coordinates: {center}\")\n",
    "print(f\"Geographic bounds: {bounds}\")\n",
    "print(f\"Time range: {starttime} to {endtime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-source-config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data sources based on region\n",
    "data_sources = region_config.config.get('data_sources', {})\n",
    "\n",
    "# Default data source configuration\n",
    "if region_name.lower() in [\"demo\", \"california\"]:\n",
    "    client = \"SCEDC\"\n",
    "    network_list = [\"CI\"]\n",
    "    channel_list = \"HH*,BH*,EH*,HN*\"\n",
    "elif region_name.lower() == \"japan\":\n",
    "    client = \"NIED\"\n",
    "    network_list = [\"N.NIED\"]\n",
    "    channel_list = \"HH*,BH*,EH*\"\n",
    "elif region_name.lower() == \"hawaii\":\n",
    "    client = \"IRIS\"\n",
    "    network_list = [\"HV\", \"PT\"]\n",
    "    channel_list = \"HH*,BH*,EH*,HN*\"\n",
    "else:\n",
    "    # Use data sources from config if available\n",
    "    waveform_config = data_sources.get('waveforms', {})\n",
    "    client = waveform_config.get('provider', 'IRIS')\n",
    "    network_list = [\"*\"]\n",
    "    channel_list = \"HH*,BH*,EH*,HN*\"\n",
    "\n",
    "print(f\"Data client: {client}\")\n",
    "print(f\"Networks: {network_list}\")\n",
    "print(f\"Channels: {channel_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unified-config-creation-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced configuration dictionary\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "degree2km = np.pi * 6371 / 180\n",
    "\n",
    "# Enhanced configuration with unified framework integration\n",
    "config = {\n",
    "    \"region\": region_name,\n",
    "    \"center\": center,\n",
    "    \"xlim_degree\": [bounds['minlongitude'], bounds['maxlongitude']],\n",
    "    \"ylim_degree\": [bounds['minlatitude'], bounds['maxlatitude']],\n",
    "    \"min_longitude\": bounds['minlongitude'],\n",
    "    \"max_longitude\": bounds['maxlongitude'],\n",
    "    \"min_latitude\": bounds['minlatitude'],\n",
    "    \"max_latitude\": bounds['maxlatitude'],\n",
    "    \"degree2km\": degree2km,\n",
    "    \"starttime\": starttime.datetime.isoformat(timespec=\"milliseconds\"),\n",
    "    \"endtime\": endtime.datetime.isoformat(timespec=\"milliseconds\"),\n",
    "    \"networks\": network_list,\n",
    "    \"channels\": channel_list,\n",
    "    \"client\": client,\n",
    "    # Enhanced processing configuration from unified framework\n",
    "    \"phasenet\": region_config.get_processing_config('phasenet'),\n",
    "    \"gamma\": region_config.get_processing_config('gamma'),\n",
    "    \"adloc\": region_config.get_processing_config('adloc'),\n",
    "    \"hypodd\": {\"MAXEVENT\": 1e4},\n",
    "    # Add velocity model information\n",
    "    \"velocity_model\": region_config.config.get('velocity_model', {}),\n",
    "    \"quality_control\": region_config.config.get('quality_control', {})\n",
    "}\n",
    "\n",
    "print(f\"Enhanced configuration created for region: {region_name}\")\n",
    "print(f\"Processing modules configured: {list(config.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory and save configuration files\n",
    "config_dir_name = 'config'\n",
    "config_dir = Path(config_dir_name)\n",
    "config_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config_json = config_dir / 'config.json'\n",
    "datetime_json = config_dir / 'datetime.json'\n",
    "index_json = config_dir / 'index.json'\n",
    "\n",
    "# Save main configuration\n",
    "with open(config_json, \"w\") as fp:\n",
    "    json.dump(config, fp, indent=2)\n",
    "\n",
    "ElyraUtils.log_pipeline_step(\n",
    "    \"config_creation\",\n",
    "    \"completed\",\n",
    "    {\"config_file\": str(config_json), \"region\": region_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-processing-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced parallel processing configuration\n",
    "one_hour = datetime.timedelta(hours=1)\n",
    "starttimes = []\n",
    "tmp_start = starttime\n",
    "\n",
    "while tmp_start < endtime:\n",
    "    starttimes.append(tmp_start.datetime.isoformat(timespec=\"milliseconds\"))\n",
    "    tmp_start += one_hour\n",
    "\n",
    "# Save datetime configuration\n",
    "with open(datetime_json, \"w\") as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"starttimes\": starttimes, \n",
    "            \"interval\": one_hour.total_seconds(),\n",
    "            \"region\": region_name,\n",
    "            \"total_hours\": len(starttimes)\n",
    "        },\n",
    "        fp,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# Enhanced parallel processing index\n",
    "if num_parallel == 0:\n",
    "    num_parallel = min(60, max(1, int((len(starttimes) - 1) // 6 + 1)))\n",
    "\n",
    "idx = [x.tolist() for x in np.array_split(np.arange(len(starttimes)), num_parallel)]\n",
    "\n",
    "# Save index configuration with metadata\n",
    "index_config = {\n",
    "    \"indices\": idx,\n",
    "    \"num_parallel\": num_parallel,\n",
    "    \"total_time_slots\": len(starttimes),\n",
    "    \"slots_per_process\": [len(x) for x in idx],\n",
    "    \"region\": region_name\n",
    "}\n",
    "\n",
    "with open(index_json, \"w\") as fp:\n",
    "    json.dump(index_config, fp, indent=2)\n",
    "\n",
    "print(f\"Parallel processing configured:\")\n",
    "print(f\"  - Total time slots: {len(starttimes)}\")\n",
    "print(f\"  - Parallel processes: {num_parallel}\")\n",
    "print(f\"  - Slots per process: {[len(x) for x in idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artifacts-summary-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and artifact creation\n",
    "artifacts = {\n",
    "    \"config.json\": str(config_json),\n",
    "    \"datetime.json\": str(datetime_json),\n",
    "    \"index.json\": str(index_json)\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"region\": region_name,\n",
    "    \"time_slots\": len(starttimes),\n",
    "    \"parallel_processes\": num_parallel,\n",
    "    \"geographic_bounds\": f\"{bounds['minlatitude']:.2f}-{bounds['maxlatitude']:.2f}°N, {bounds['minlongitude']:.2f}-{bounds['maxlongitude']:.2f}°E\",\n",
    "    \"time_range\": f\"{starttime.date} to {endtime.date}\",\n",
    "    \"data_client\": client\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED CONFIGURATION SETUP COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "for key, value in results.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "print(\"\\nConfiguration files created:\")\n",
    "for name, path in artifacts.items():\n",
    "    print(f\"  - {name}: {path}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finalize-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize notebook with enhanced metadata\n",
    "notebook_finalize(\n",
    "    step_name=\"enhanced_config_setup\",\n",
    "    results=results,\n",
    "    artifacts=artifacts\n",
    ")\n",
    "\n",
    "print(\"Enhanced configuration setup completed successfully!\")\n",
    "print(f\"Ready for {region_name} earthquake data processing pipeline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}