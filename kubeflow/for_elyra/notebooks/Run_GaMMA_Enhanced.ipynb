{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Enhanced GaMMA Event Association for QuakeFlow Pipeline\n",
    "\n",
    "This notebook performs earthquake event association using GaMMA with the unified QuakeFlow framework.\n",
    "It leverages common utilities for better configuration management, error handling, and result validation."
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "setup-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Import common utilities and dependencies\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend for Kubeflow\n",
    "\n",
    "# Add common utilities to path\n",
    "examples_dir = Path.cwd().parent.parent / 'examples'\n",
    "if str(examples_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(examples_dir))\n",
    "\n",
    "# Import QuakeFlow common utilities\n",
    "from common import notebook_setup, notebook_finalize, ElyraUtils\n",
    "\n",
    "print(\"QuakeFlow common utilities imported successfully\")"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "initialization-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Initialize workflow with unified framework\n",
    "region_config, workflow, parallel_config = notebook_setup()\n",
    "\n",
    "region_name = region_config.region\n",
    "gamma_config = region_config.get_processing_config('gamma')\n",
    "velocity_model = region_config.get_velocity_model()\n",
    "\n",
    "print(f\"Region: {region_name}\")\n",
    "print(f\"GaMMA configuration: {gamma_config}\")\n",
    "print(f\"Velocity model: {velocity_model.get_gamma_config()}\")\n",
    "\n",
    "# Check dependencies\n",
    "required_files = [\n",
    "    'config/config.json',\n",
    "    'config/index.json', \n",
    "    'phasenet/picks.csv',\n",
    "    'stations/stations.json'\n",
    "]\n",
    "dependencies_ok = ElyraUtils.check_dependencies(required_files)\n",
    "\n",
    "if not dependencies_ok:\n",
    "    raise FileNotFoundError(\"Required input files are missing. Please check pipeline dependencies.\")"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "data-loading-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Enhanced data loading with validation\n",
    "try:\n",
    "    ElyraUtils.log_pipeline_step(\"data_loading\", \"starting\")\n",
    "    \n",
    "    # Load configuration\n",
    "    with open('config/config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Load picks using unified framework\n",
    "    picks = workflow.load_picks('phasenet/picks.csv')\n",
    "    \n",
    "    # Load stations using unified framework\n",
    "    stations = workflow.load_stations('stations/stations.json')\n",
    "    \n",
    "    # Enhanced data validation\n",
    "    picks_validation = {\n",
    "        \"total_picks\": len(picks),\n",
    "        \"required_columns\": all(col in picks.columns for col in ['station_id', 'phase_time', 'phase_type']),\n",
    "        \"unique_stations\": picks['station_id'].nunique() if 'station_id' in picks.columns else 0,\n",
    "        \"p_picks\": len(picks[picks['phase_type'] == 'P']) if 'phase_type' in picks.columns else 0,\n",
    "        \"s_picks\": len(picks[picks['phase_type'] == 'S']) if 'phase_type' in picks.columns else 0\n",
    "    }\n",
    "    \n",
    "    stations_validation = {\n",
    "        \"total_stations\": len(stations),\n",
    "        \"required_columns\": all(col in stations.columns for col in ['id', 'longitude', 'latitude']),\n",
    "        \"coordinate_transformed\": all(col in stations.columns for col in ['x_km', 'y_km', 'z_km'])\n",
    "    }\n",
    "    \n",
    "    ElyraUtils.log_pipeline_step(\n",
    "        \"data_loading\",\n",
    "        \"completed\",\n",
    "        {\n",
    "            \"picks_validation\": picks_validation,\n",
    "            \"stations_validation\": stations_validation\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Check minimum requirements for GaMMA\n",
    "    min_picks_required = gamma_config.get('min_picks_per_eq', 6)\n",
    "    if picks_validation['total_picks'] < min_picks_required:\n",
    "        ElyraUtils.log_pipeline_step(\n",
    "            \"gamma_validation\", \n",
    "            \"warning\", \n",
    "            {\"issue\": f\"Only {picks_validation['total_picks']} picks available, minimum {min_picks_required} recommended\"}\n",
    "        )\n",
    "        \n",
    "except Exception as e:\n",
    "    ElyraUtils.log_pipeline_step(\"data_loading\", \"failed\", {\"error\": str(e)})\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "gamma-processing-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Enhanced GaMMA processing with unified framework\n",
    "try:\n",
    "    ElyraUtils.log_pipeline_step(\"gamma_processing\", \"starting\")\n",
    "    \n",
    "    # Get GaMMA parameters from unified configuration\n",
    "    method = gamma_config.get('method', 'BGMM')\n",
    "    use_amplitude = gamma_config.get('use_amplitude', True)\n",
    "    oversample_factor = gamma_config.get('oversample_factor', 4)\n",
    "    dims = gamma_config.get('dims', ['x_km', 'y_km', 'z_km'])\n",
    "    \n",
    "    # Process using unified workflow\n",
    "    events, associated_picks = workflow.gamma.associate_events(\n",
    "        picks_file='phasenet/picks.csv',\n",
    "        stations_file='stations/stations.json',\n",
    "        output_dir='gamma'\n",
    "    )\n",
    "    \n",
    "    # Enhanced results analysis\n",
    "    association_stats = {\n",
    "        \"total_events\": len(events),\n",
    "        \"total_associated_picks\": len(associated_picks),\n",
    "        \"association_rate\": len(associated_picks) / len(picks) if len(picks) > 0 else 0,\n",
    "        \"avg_picks_per_event\": len(associated_picks) / len(events) if len(events) > 0 else 0,\n",
    "        \"method_used\": method,\n",
    "        \"amplitude_used\": use_amplitude\n",
    "    }\n",
    "    \n",
    "    # Magnitude analysis if available\n",
    "    if 'magnitude' in events.columns and len(events) > 0:\n",
    "        association_stats.update({\n",
    "            \"magnitude_range\": [events['magnitude'].min(), events['magnitude'].max()],\n",
    "            \"mean_magnitude\": events['magnitude'].mean(),\n",
    "            \"events_above_m2\": len(events[events['magnitude'] >= 2.0])\n",
    "        })\n",
    "    \n",
    "    ElyraUtils.log_pipeline_step(\n",
    "        \"gamma_processing\",\n",
    "        \"completed\",\n",
    "        association_stats\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    ElyraUtils.log_pipeline_step(\"gamma_processing\", \"failed\", {\"error\": str(e)})\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "quality-control-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Enhanced quality control and filtering\n",
    "try:\n",
    "    ElyraUtils.log_pipeline_step(\"quality_control\", \"starting\")\n",
    "    \n",
    "    quality_config = region_config.config.get('quality_control', {})\n",
    "    \n",
    "    original_event_count = len(events)\n",
    "    original_pick_count = len(associated_picks)\n",
    "    \n",
    "    # Apply quality filters\n",
    "    filtered_events = events.copy()\n",
    "    filtered_picks = associated_picks.copy()\n",
    "    \n",
    "    # Magnitude filter\n",
    "    if 'min_magnitude' in quality_config and 'magnitude' in filtered_events.columns:\n",
    "        min_mag = quality_config['min_magnitude']\n",
    "        filtered_events = filtered_events[filtered_events['magnitude'] >= min_mag]\n",
    "    \n",
    "    # Depth filter\n",
    "    if 'max_depth' in quality_config and 'depth_km' in filtered_events.columns:\n",
    "        max_depth = quality_config['max_depth']\n",
    "        filtered_events = filtered_events[filtered_events['depth_km'] <= max_depth]\n",
    "    \n",
    "    # Minimum picks per event filter\n",
    "    if 'min_picks_per_event' in quality_config and 'num_picks' in filtered_events.columns:\n",
    "        min_picks = quality_config['min_picks_per_event']\n",
    "        filtered_events = filtered_events[filtered_events['num_picks'] >= min_picks]\n",
    "    \n",
    "    # Filter picks based on remaining events\n",
    "    if len(filtered_events) < len(events):\n",
    "        valid_event_ids = set(filtered_events['event_id'])\n",
    "        filtered_picks = filtered_picks[filtered_picks['event_id'].isin(valid_event_ids)]\n",
    "    \n",
    "    quality_stats = {\n",
    "        \"original_events\": original_event_count,\n",
    "        \"filtered_events\": len(filtered_events),\n",
    "        \"events_removed\": original_event_count - len(filtered_events),\n",
    "        \"original_picks\": original_pick_count,\n",
    "        \"filtered_picks\": len(filtered_picks),\n",
    "        \"picks_removed\": original_pick_count - len(filtered_picks),\n",
    "        \"filters_applied\": list(quality_config.keys())\n",
    "    }\n",
    "    \n",
    "    # Save filtered results\n",
    "    filtered_events.to_csv('gamma/gamma_catalog_filtered.csv', index=False)\n",
    "    filtered_picks.to_csv('gamma/gamma_picks_filtered.csv', index=False)\n",
    "    \n",
    "    ElyraUtils.log_pipeline_step(\n",
    "        \"quality_control\",\n",
    "        \"completed\",\n",
    "        quality_stats\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    ElyraUtils.log_pipeline_step(\"quality_control\", \"failed\", {\"error\": str(e)})\n",
    "    # Continue with unfiltered data if quality control fails\n",
    "    filtered_events = events\n",
    "    filtered_picks = associated_picks\n",
    "    quality_stats = {\"status\": \"failed\", \"using_unfiltered_data\": True}"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "visualization-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Enhanced visualization with unified framework\n",
    "try:\n",
    "    ElyraUtils.log_pipeline_step(\"visualization\", \"starting\")\n",
    "    \n",
    "    # Create output directory\n",
    "    Path('gamma/figures').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Geographic bounds for plotting\n",
    "    bounds = region_config.get_geographic_bounds()\n",
    "    \n",
    "    # 1. Event location map\n",
    "    if len(filtered_events) > 0 and 'longitude' in filtered_events.columns:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Plot events with magnitude-based sizing if available\n",
    "        if 'magnitude' in filtered_events.columns:\n",
    "            sizes = (filtered_events['magnitude'] - filtered_events['magnitude'].min() + 1) * 20\n",
    "            scatter = plt.scatter(\n",
    "                filtered_events['longitude'], \n",
    "                filtered_events['latitude'],\n",
    "                c=filtered_events['magnitude'], \n",
    "                s=sizes,\n",
    "                cmap='viridis',\n",
    "                alpha=0.7,\n",
    "                edgecolors='black',\n",
    "                linewidth=0.5\n",
    "            )\n",
    "            plt.colorbar(scatter, label='Magnitude')\n",
    "        else:\n",
    "            plt.scatter(\n",
    "                filtered_events['longitude'], \n",
    "                filtered_events['latitude'],\n",
    "                alpha=0.7,\n",
    "                edgecolors='black',\n",
    "                linewidth=0.5\n",
    "            )\n",
    "        \n",
    "        # Plot stations\n",
    "        plt.scatter(\n",
    "            stations['longitude'], \n",
    "            stations['latitude'],\n",
    "            marker='^', \n",
    "            c='red', \n",
    "            s=30, \n",
    "            label='Stations',\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.title(f'GaMMA Event Locations - {region_name}\\n{len(filtered_events)} events')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axis('equal')\n",
    "        \n",
    "        # Set reasonable plot bounds\n",
    "        plt.xlim(bounds['minlongitude'] - 0.1, bounds['maxlongitude'] + 0.1)\n",
    "        plt.ylim(bounds['minlatitude'] - 0.1, bounds['maxlatitude'] + 0.1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gamma/figures/event_locations.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Magnitude-time plot\n",
    "    if len(filtered_events) > 0 and 'magnitude' in filtered_events.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Convert origin_time to datetime if needed\n",
    "        if 'origin_time' in filtered_events.columns:\n",
    "            times = pd.to_datetime(filtered_events['origin_time'])\n",
    "            plt.scatter(times, filtered_events['magnitude'], alpha=0.7)\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Magnitude')\n",
    "            plt.title(f'Magnitude vs Time - {region_name}')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('gamma/figures/magnitude_time.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    # 3. Association statistics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create summary statistics plot\n",
    "    stats_data = [\n",
    "        len(picks),\n",
    "        len(associated_picks),\n",
    "        len(filtered_events),\n",
    "        len(stations)\n",
    "    ]\n",
    "    stats_labels = [\n",
    "        'Total Picks',\n",
    "        'Associated Picks', \n",
    "        'Events',\n",
    "        'Stations'\n",
    "    ]\n",
    "    \n",
    "    bars = plt.bar(stats_labels, stats_data, color=['skyblue', 'lightgreen', 'orange', 'lightcoral'])\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'GaMMA Processing Summary - {region_name}')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, stats_data):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(stats_data)*0.01,\n",
    "                str(value), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gamma/figures/processing_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    visualization_files = [\n",
    "        'gamma/figures/event_locations.png',\n",
    "        'gamma/figures/magnitude_time.png',\n",
    "        'gamma/figures/processing_summary.png'\n",
    "    ]\n",
    "    \n",
    "    ElyraUtils.log_pipeline_step(\n",
    "        \"visualization\",\n",
    "        \"completed\",\n",
    "        {\"figures_created\": len([f for f in visualization_files if os.path.exists(f)])}\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    ElyraUtils.log_pipeline_step(\"visualization\", \"failed\", {\"error\": str(e)})\n",
    "    visualization_files = []"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "output-organization-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Enhanced output organization and metadata creation\n",
    "artifacts = {}\n",
    "\n",
    "# Standard GaMMA outputs\n",
    "if os.path.exists('gamma/gamma_catalog.csv'):\n",
    "    artifacts['gamma_catalog.csv'] = 'gamma/gamma_catalog.csv'\n",
    "if os.path.exists('gamma/gamma_picks.csv'):\n",
    "    artifacts['gamma_picks.csv'] = 'gamma/gamma_picks.csv'\n",
    "\n",
    "# Quality-controlled outputs\n",
    "if os.path.exists('gamma/gamma_catalog_filtered.csv'):\n",
    "    artifacts['gamma_catalog_filtered.csv'] = 'gamma/gamma_catalog_filtered.csv'\n",
    "if os.path.exists('gamma/gamma_picks_filtered.csv'):\n",
    "    artifacts['gamma_picks_filtered.csv'] = 'gamma/gamma_picks_filtered.csv'\n",
    "\n",
    "# Visualization outputs\n",
    "for fig_file in visualization_files:\n",
    "    if os.path.exists(fig_file):\n",
    "        artifacts[os.path.basename(fig_file)] = fig_file\n",
    "\n",
    "# Create comprehensive processing summary\n",
    "processing_summary = {\n",
    "    \"region\": region_name,\n",
    "    \"input_data\": {\n",
    "        \"total_picks\": len(picks),\n",
    "        \"stations_used\": len(stations),\n",
    "        \"time_range\": f\"{config.get('starttime', 'N/A')} to {config.get('endtime', 'N/A')}\"\n",
    "    },\n",
    "    \"association_results\": association_stats,\n",
    "    \"quality_control\": quality_stats,\n",
    "    \"final_output\": {\n",
    "        \"events\": len(filtered_events),\n",
    "        \"associated_picks\": len(filtered_picks),\n",
    "        \"association_rate\": len(filtered_picks) / len(picks) if len(picks) > 0 else 0\n",
    "    },\n",
    "    \"processing_parameters\": {\n",
    "        \"method\": gamma_config.get('method', 'BGMM'),\n",
    "        \"use_amplitude\": gamma_config.get('use_amplitude', True),\n",
    "        \"velocity_model\": velocity_model.get_gamma_config(),\n",
    "        \"quality_filters\": quality_config\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save processing summary\n",
    "summary_file = 'gamma/processing_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(processing_summary, f, indent=2)\n",
    "\n",
    "artifacts['processing_summary.json'] = summary_file\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENHANCED GAMMA PROCESSING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Region: {region_name}\")\n",
    "print(f\"Input picks: {len(picks)}\")\n",
    "print(f\"Events detected: {len(filtered_events)}\")\n",
    "print(f\"Associated picks: {len(filtered_picks)}\")\n",
    "print(f\"Association rate: {len(filtered_picks) / len(picks) * 100:.1f}%\")\n",
    "if 'magnitude_range' in association_stats:\n",
    "    mag_range = association_stats['magnitude_range']\n",
    "    print(f\"Magnitude range: {mag_range[0]:.1f} - {mag_range[1]:.1f}\")\n",
    "print(f\"\\nGenerated Files: {len(artifacts)}\")\n",
    "for name, path in artifacts.items():\n",
    "    print(f\"  - {name}: {path}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",\n",
   "execution_count": null,\n",
   "id": "finalize-cell",\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Finalize notebook with enhanced metadata and results\n",
    "results = {\n",
    "    \"total_events\": len(filtered_events),\n",
    "    \"associated_picks\": len(filtered_picks),\n",
    "    \"association_rate\": len(filtered_picks) / len(picks) if len(picks) > 0 else 0,\n",
    "    \"input_picks\": len(picks),\n",
    "    \"stations_used\": len(stations)\n",
    "}\n",
    "\n",
    "if 'magnitude_range' in association_stats:\n",
    "    results.update({\n",
    "        \"min_magnitude\": association_stats['magnitude_range'][0],\n",
    "        \"max_magnitude\": association_stats['magnitude_range'][1],\n",
    "        \"mean_magnitude\": association_stats['mean_magnitude']\n",
    "    })\n",
    "\n",
    "notebook_finalize(\n",
    "    step_name=\"enhanced_gamma_processing\",\n",
    "    results=results,\n",
    "    artifacts=artifacts\n",
    ")\n",
    "\n",
    "print(f\"Enhanced GaMMA processing completed for {region_name}!\")\n",
    "print(f\"Associated {len(filtered_picks)} picks into {len(filtered_events)} events\")\n",
    "print(f\"Association rate: {len(filtered_picks) / len(picks) * 100:.1f}%\")\n",
    "print(\"Ready for ADLoc event relocation phase.\")"
   ]
  }\n",
 ],\n",
 \"metadata\": {\n",
  \"kernelspec\": {\n",
   \"display_name\": \"Python 3\",\n",
   \"language\": \"python\",\n",
   \"name\": \"python3\"\n",
  },\n",
  \"language_info\": {\n",
   \"codemirror_mode\": {\n",
    \"name\": \"ipython\",\n",
    \"version\": 3\n",
   },\n",
   \"file_extension\": \".py\",\n",
   \"mimetype\": \"text/x-python\",\n",
   \"name\": \"python\",\n",
   \"nbconvert_exporter\": \"python\",\n",
   \"pygments_lexer\": \"ipython3\",\n",
   \"version\": \"3.9.0\"\n",
  }\n",
 },\n",
 \"nbformat\": 4,\n",
 \"nbformat_minor\": 5\n",
}