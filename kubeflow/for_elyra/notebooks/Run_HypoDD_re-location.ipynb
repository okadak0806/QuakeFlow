{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# HypoDD Re-location\n",
    "\n",
    "This notebook performs earthquake re-location using HypoDD method based on catalog travel times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "node_i = 0\n",
    "bucket_name = \"catalogs\"\n",
    "s3_url = \"minio-service:9000\"\n",
    "secure = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcea2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from minio import Minio\n",
    "import subprocess\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d846dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"config/config.json\"\n",
    "with open(config_path, \"r\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "region_name = config[\"region\"]\n",
    "print(f\"Processing region: {region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for files downloaded by Elyra\n",
    "# Elyra downloads files to the current directory structure\n",
    "elyra_ct_file = f\"hypodd/dt.ct\"\n",
    "elyra_event_file = f\"hypodd/event.sel\"\n",
    "elyra_station_file = f\"hypodd/stations.dat\"\n",
    "elyra_cc_file = f\"hypodd/dt.cc\"  # May not exist\n",
    "\n",
    "print(\"Checking files downloaded by Elyra:\")\n",
    "for file_path, description in [\n",
    "    (elyra_ct_file, \"CT differential times\"),\n",
    "    (elyra_event_file, \"Event file\"),\n",
    "    (elyra_station_file, \"Station file\"),\n",
    "    (elyra_cc_file, \"CC differential times\")\n",
    "]:\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"  ✓ {description}: {file_path} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"  ✗ {description}: {file_path} (NOT FOUND)\")\n",
    "\n",
    "# Check if CC data is available\n",
    "cc_available = os.path.exists(elyra_cc_file) and os.path.getsize(elyra_cc_file) > 0\n",
    "print(f\"\\nCC data available: {cc_available}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd28927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup working directory structure in current directory\n",
    "work_dir = \"work\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "# Create HypoDD working directories\n",
    "hypodd_ct_path = f\"{work_dir}/hypodd_ct\"\n",
    "hypodd_cc_path = f\"{work_dir}/hypodd_cc\"\n",
    "os.makedirs(hypodd_ct_path, exist_ok=True)\n",
    "os.makedirs(hypodd_cc_path, exist_ok=True)\n",
    "print(f\"Created working directories:\")\n",
    "print(f\"  CT: {hypodd_ct_path}\")\n",
    "print(f\"  CC: {hypodd_cc_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b73d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify required files exist\n",
    "required_files = [\n",
    "    (elyra_ct_file, \"CT differential times\"),\n",
    "    (elyra_event_file, \"Event file\"),\n",
    "    (elyra_station_file, \"Station file\")\n",
    "]\n",
    "\n",
    "for file_path, description in required_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Required file not found: {file_path} ({description})\")\n",
    "    if os.path.getsize(file_path) == 0:\n",
    "        raise ValueError(f\"Required file is empty: {file_path} ({description})\")\n",
    "\n",
    "print(\"All required files verified successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HypoDD CT configuration \n",
    "ct_inp_content = \"\"\"* RELOC.INP:\n",
    "*--- input file selection\n",
    "* cross correlation diff times:\n",
    "\n",
    "*\n",
    "*catalog P diff times:\n",
    "dt.ct\n",
    "*\n",
    "* event file:\n",
    "event.sel\n",
    "*\n",
    "* station file:\n",
    "stations.dat\n",
    "*\n",
    "*--- output file selection\n",
    "* original locations:\n",
    "hypodd.loc\n",
    "* relocations:\n",
    "hypodd.reloc\n",
    "* station information:\n",
    "hypodd.sta\n",
    "* residual information:\n",
    "hypodd.res\n",
    "* source paramater information:\n",
    "hypodd.src\n",
    "*\n",
    "*--- data type selection: \n",
    "* IDAT:  0 = synthetics; 1= cross corr; 2= catalog; 3= cross & cat \n",
    "* IPHA: 1= P; 2= S; 3= P&S\n",
    "* DIST:max dist [km] between cluster centroid and station \n",
    "* IDAT   IPHA   DIST\n",
    "    2     3     120\n",
    "*\n",
    "*--- event clustering:\n",
    "* OBSCC:    min # of obs/pair for crosstime data (0= no clustering)\n",
    "* OBSCT:    min # of obs/pair for network data (0= no clustering)\n",
    "* OBSCC  OBSCT    \n",
    "     0     8        \n",
    "*\n",
    "*--- solution control:\n",
    "* ISTART:  \t1 = from single source; 2 = from network sources\n",
    "* ISOLV:\t1 = SVD, 2=lsqr\n",
    "* NSET:      \tnumber of sets of iteration with specifications following\n",
    "*  ISTART  ISOLV  NSET\n",
    "    2        2      4\n",
    "*\n",
    "*--- data weighting and re-weighting: \n",
    "* NITER: \t\tlast iteration to used the following weights\n",
    "* WTCCP, WTCCS:\t\tweight cross P, S \n",
    "* WTCTP, WTCTS:\t\tweight catalog P, S \n",
    "* WRCC, WRCT:\t\tresidual threshold in sec for cross, catalog data \n",
    "* WDCC, WDCT:  \t\tmax dist [km] between cross, catalog linked pairs\n",
    "* DAMP:    \t\tdamping (for lsqr only) \n",
    "*       ---  CROSS DATA ----- ----CATALOG DATA ----\n",
    "* NITER WTCCP WTCCS WRCC WDCC WTCTP WTCTS WRCT WDCT DAMP\n",
    "   4     -9     -9   -9    -9   1     1      8   -9  70 \n",
    "   4     -9     -9   -9    -9   1     1      6    4  70 \n",
    "   4     -9     -9   -9    -9   1    0.8     4    2  70 \n",
    "   4     -9     -9   -9    -9   1    0.8     3    2  70 \n",
    "*\n",
    "*--- 1D model:\n",
    "* NLAY:\tnumber of model layers  \n",
    "* RATIO:\tvp/vs ratio \n",
    "* TOP:\tdepths of top of layer (km) \n",
    "* VEL: \tlayer velocities (km/s)\n",
    "* NLAY  RATIO \n",
    "   12     1.82\n",
    "* TOP \n",
    "0.0 1.0 3.0 5.0 7.0 9.0 11.0 13.0 17.0 21.0 31.00 31.10\n",
    "* VEL\n",
    "5.30 5.65 5.93 6.20 6.20 6.20 6.20 6.20 6.20 6.20 7.50 8.11\n",
    "*\n",
    "*--- event selection:\n",
    "* CID: \tcluster to be relocated (0 = all)\n",
    "* ID:\tcuspids of event to be relocated (8 per line)\n",
    "* CID    \n",
    "    0      \n",
    "* ID\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(hypodd_ct_path, \"ct.inp\"), \"w\") as fp:\n",
    "    fp.write(ct_inp_content)\n",
    "print(\"Created HypoDD CT configuration file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy input files to CT working directory\n",
    "def copy_file(fp_from, fp_to):\n",
    "    with open(fp_from, \"r\") as fp:\n",
    "        lines = fp.readlines()\n",
    "    with open(fp_to, \"w\") as fp:\n",
    "        fp.writelines(lines)\n",
    "\n",
    "copy_file(elyra_ct_file, os.path.join(hypodd_ct_path, \"dt.ct\"))\n",
    "copy_file(elyra_event_file, os.path.join(hypodd_ct_path, \"event.sel\"))\n",
    "copy_file(elyra_station_file, os.path.join(hypodd_ct_path, \"stations.dat\"))\n",
    "print(\"Copied input files to CT working directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display CT input file info\n",
    "print(\"CT input file sizes:\")\n",
    "for filename in [\"dt.ct\", \"event.sel\", \"stations.dat\"]:\n",
    "    filepath = os.path.join(hypodd_ct_path, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"  {filename}: {size} bytes\")\n",
    "        if size == 0:\n",
    "            print(f\"  WARNING: {filename} is empty!\")\n",
    "    else:\n",
    "        print(f\"  {filename}: NOT FOUND\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HypoDD CT\n",
    "print(\"=\" * 50)\n",
    "print(\"RUNNING HYPODD CT PROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "HYPODD_CT_CMD = [\"hypoDD\", \"ct.inp\"]\n",
    "print(f\"Running HypoDD CT command: {' '.join(HYPODD_CT_CMD)}\")\n",
    "print(f\"Working directory: {hypodd_ct_path}\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        HYPODD_CT_CMD,\n",
    "        cwd=hypodd_ct_path,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    print(\"HypoDD CT completed successfully\")\n",
    "    print(\"STDOUT:\")\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\")\n",
    "        print(result.stderr)\n",
    "        \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"HypoDD CT failed with return code {e.returncode}\")\n",
    "    print(\"STDOUT:\")\n",
    "    print(e.stdout)\n",
    "    print(\"STDERR:\")\n",
    "    print(e.stderr)\n",
    "    raise\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"HypoDD executable not found: {e}\")\n",
    "    print(\"Available files in CT working directory:\")\n",
    "    for f in os.listdir(hypodd_ct_path):\n",
    "        print(f\"  {f}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CT output files\n",
    "output_files = [\"hypodd.reloc\", \"hypodd.loc\", \"hypodd.sta\", \"hypodd.res\", \"hypodd.src\"]\n",
    "print(\"CT output file status:\")\n",
    "for filename in output_files:\n",
    "    filepath = os.path.join(hypodd_ct_path, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"  {filename}: {size} bytes\")\n",
    "    else:\n",
    "        print(f\"  {filename}: NOT FOUND\")\n",
    "\n",
    "# Check if main CT output file exists\n",
    "ct_reloc_file = os.path.join(hypodd_ct_path, \"hypodd.reloc\")\n",
    "if not os.path.exists(ct_reloc_file):\n",
    "    print(\"ERROR: HypoDD CT hypodd.reloc file was not created!\")\n",
    "    print(\"CT working directory contents:\")\n",
    "    for f in os.listdir(hypodd_ct_path):\n",
    "        print(f\"  {f}\")\n",
    "    raise FileNotFoundError(\"HypoDD CT output file not created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339533b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy CT output file to final location\n",
    "outputs_dir = \"hypo_reloc\"\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "catalog_ct_path = f\"{outputs_dir}/hypodd_ct_{node_i:03d}.reloc\"\n",
    "copy_file(ct_reloc_file, catalog_ct_path)\n",
    "print(f\"CT output catalog saved to: {catalog_ct_path}\")\n",
    "\n",
    "# Display first few lines of CT output\n",
    "if os.path.exists(catalog_ct_path):\n",
    "    with open(catalog_ct_path, \"r\") as f:\n",
    "        lines = f.readlines()[:10]\n",
    "    print(\"\\nFirst 10 lines of CT output catalog:\")\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        print(f\"{i:2d}: {line.rstrip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26681fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CC if available\n",
    "catalog_cc_path = f\"{outputs_dir}/hypodd_cc_{node_i:03d}.reloc\"\n",
    "if cc_available:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"RUNNING HYPODD CC PROCESSING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create CC configuration\n",
    "    cc_inp_content = \"\"\"* RELOC.INP:\n",
    "*--- input file selection\n",
    "* cross correlation diff times:\n",
    "dt.cc\n",
    "*\n",
    "*catalog P diff times:\n",
    "dt.ct\n",
    "*\n",
    "* event file:\n",
    "event.sel\n",
    "*\n",
    "* station file:\n",
    "stations.dat\n",
    "*\n",
    "*--- output file selection\n",
    "* original locations:\n",
    "hypodd.loc\n",
    "* relocations:\n",
    "hypodd.reloc\n",
    "* station information:\n",
    "hypodd.sta\n",
    "* residual information:\n",
    "hypodd.res\n",
    "* source paramater information:\n",
    "hypodd.src\n",
    "*\n",
    "*--- data type selection: \n",
    "* IDAT:  0 = synthetics; 1= cross corr; 2= catalog; 3= cross & cat \n",
    "* IPHA: 1= P; 2= S; 3= P&S\n",
    "* DIST:max dist [km] between cluster centroid and station \n",
    "* IDAT   IPHA   DIST\n",
    "    3     3     120\n",
    "*\n",
    "*--- event clustering:\n",
    "* OBSCC:    min # of obs/pair for crosstime data (0= no clustering)\n",
    "* OBSCT:    min # of obs/pair for network data (0= no clustering)\n",
    "* OBSCC  OBSCT    \n",
    "     8     8        \n",
    "*\n",
    "*--- solution control:\n",
    "* ISTART:  \t1 = from single source; 2 = from network sources\n",
    "* ISOLV:\t1 = SVD, 2=lsqr\n",
    "* NSET:      \tnumber of sets of iteration with specifications following\n",
    "*  ISTART  ISOLV  NSET\n",
    "    2        2      4\n",
    "*\n",
    "*--- data weighting and re-weighting: \n",
    "* NITER: \t\tlast iteration to used the following weights\n",
    "* WTCCP, WTCCS:\t\tweight cross P, S \n",
    "* WTCTP, WTCTS:\t\tweight catalog P, S \n",
    "* WRCC, WRCT:\t\tresidual threshold in sec for cross, catalog data \n",
    "* WDCC, WDCT:  \t\tmax dist [km] between cross, catalog linked pairs\n",
    "* DAMP:    \t\tdamping (for lsqr only) \n",
    "*       ---  CROSS DATA ----- ----CATALOG DATA ----\n",
    "* NITER WTCCP WTCCS WRCC WDCC WTCTP WTCTS WRCT WDCT DAMP\n",
    "   4    1.0   1.0   6    2   1.0   1.0     8   -9  70 \n",
    "   4    1.0   1.0   4    2   1.0   1.0     6    4  70 \n",
    "   4    1.0   1.0   3    2   1.0   0.8     4    2  70 \n",
    "   4    1.0   1.0   2    2   1.0   0.8     3    2  70 \n",
    "*\n",
    "*--- 1D model:\n",
    "* NLAY:\tnumber of model layers  \n",
    "* RATIO:\tvp/vs ratio \n",
    "* TOP:\tdepths of top of layer (km) \n",
    "* VEL: \tlayer velocities (km/s)\n",
    "* NLAY  RATIO \n",
    "   12     1.82\n",
    "* TOP \n",
    "0.0 1.0 3.0 5.0 7.0 9.0 11.0 13.0 17.0 21.0 31.00 31.10\n",
    "* VEL\n",
    "5.30 5.65 5.93 6.20 6.20 6.20 6.20 6.20 6.20 6.20 7.50 8.11\n",
    "*\n",
    "*--- event selection:\n",
    "* CID: \tcluster to be relocated (0 = all)\n",
    "* ID:\tcuspids of event to be relocated (8 per line)\n",
    "* CID    \n",
    "    0      \n",
    "* ID\n",
    "\"\"\"\n",
    "    \n",
    "    # Create CC configuration file\n",
    "    with open(os.path.join(hypodd_cc_path, \"cc.inp\"), \"w\") as fp:\n",
    "        fp.write(cc_inp_content)\n",
    "    print(\"Created HypoDD CC configuration file\")\n",
    "    \n",
    "    # Copy input files to CC working directory\n",
    "    copy_file(elyra_ct_file, os.path.join(hypodd_cc_path, \"dt.ct\"))\n",
    "    copy_file(elyra_cc_file, os.path.join(hypodd_cc_path, \"dt.cc\"))\n",
    "    copy_file(elyra_event_file, os.path.join(hypodd_cc_path, \"event.sel\"))\n",
    "    copy_file(elyra_station_file, os.path.join(hypodd_cc_path, \"stations.dat\"))\n",
    "    print(\"Copied input files to CC working directory\")\n",
    "    \n",
    "    # Display CC input file info\n",
    "    print(\"CC input file sizes:\")\n",
    "    for filename in [\"dt.ct\", \"dt.cc\", \"event.sel\", \"stations.dat\"]:\n",
    "        filepath = os.path.join(hypodd_cc_path, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            size = os.path.getsize(filepath)\n",
    "            print(f\"  {filename}: {size} bytes\")\n",
    "            if size == 0:\n",
    "                print(f\"  WARNING: {filename} is empty!\")\n",
    "        else:\n",
    "            print(f\"  {filename}: NOT FOUND\")\n",
    "    \n",
    "    # Run HypoDD CC\n",
    "    HYPODD_CC_CMD = [\"hypoDD\", \"cc.inp\"]\n",
    "    print(f\"Running HypoDD CC command: {' '.join(HYPODD_CC_CMD)}\")\n",
    "    print(f\"Working directory: {hypodd_cc_path}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            HYPODD_CC_CMD,\n",
    "            cwd=hypodd_cc_path,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        print(\"HypoDD CC completed successfully\")\n",
    "        print(\"STDOUT:\")\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        # Check CC output files\n",
    "        print(\"CC output file status:\")\n",
    "        for filename in output_files:\n",
    "            filepath = os.path.join(hypodd_cc_path, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                size = os.path.getsize(filepath)\n",
    "                print(f\"  {filename}: {size} bytes\")\n",
    "            else:\n",
    "                print(f\"  {filename}: NOT FOUND\")\n",
    "        \n",
    "        # Copy CC output file\n",
    "        cc_reloc_file = os.path.join(hypodd_cc_path, \"hypodd.reloc\")\n",
    "        if os.path.exists(cc_reloc_file):\n",
    "            copy_file(cc_reloc_file, catalog_cc_path)\n",
    "            print(f\"CC output catalog saved to: {catalog_cc_path}\")\n",
    "            \n",
    "            # Display first few lines of CC output\n",
    "            with open(catalog_cc_path, \"r\") as f:\n",
    "                lines = f.readlines()[:10]\n",
    "            print(\"\\nFirst 10 lines of CC output catalog:\")\n",
    "            for i, line in enumerate(lines, 1):\n",
    "                print(f\"{i:2d}: {line.rstrip()}\")\n",
    "        else:\n",
    "            print(\"ERROR: HypoDD CC hypodd.reloc file was not created!\")\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"HypoDD CC failed with return code {e.returncode}\")\n",
    "        print(\"STDOUT:\")\n",
    "        print(e.stdout)\n",
    "        print(\"STDERR:\")\n",
    "        print(e.stderr)\n",
    "        print(\"Continuing without CC results...\")\n",
    "        # Create empty CC file for pipeline compatibility\n",
    "        with open(catalog_cc_path, \"w\") as f:\n",
    "            f.write(\"# CC processing failed - empty file\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"HypoDD executable not found for CC: {e}\")\n",
    "        print(\"Continuing without CC results...\")\n",
    "        # Create empty CC file for pipeline compatibility\n",
    "        with open(catalog_cc_path, \"w\") as f:\n",
    "            f.write(\"# HypoDD executable not found - empty file\\n\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nCC processing skipped (no CC data available)\")\n",
    "    print(\"Creating empty CC output file for pipeline compatibility\")\n",
    "    with open(catalog_cc_path, \"w\") as f:\n",
    "        f.write(\"# No CC data available - empty file\\n\")\n",
    "    print(f\"Empty CC file created: {catalog_cc_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output metadata for Kubeflow UI\n",
    "ct_size = os.path.getsize(catalog_ct_path) if os.path.exists(catalog_ct_path) else 0\n",
    "cc_size = os.path.getsize(catalog_cc_path) if catalog_cc_path and os.path.exists(catalog_cc_path) else 0\n",
    "\n",
    "metadata = {\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"type\": \"table\",\n",
    "            \"storage\": \"inline\",\n",
    "            \"format\": \"csv\",\n",
    "            \"header\": [\"Metric\", \"Value\"],\n",
    "            \"source\": [\n",
    "                [\"Region\", region_name],\n",
    "                [\"Node Index\", str(node_i)],\n",
    "                [\"CT Output File\", f\"hypodd_ct_{node_i:03d}.reloc\"],\n",
    "                [\"CT File Size (bytes)\", str(ct_size)],\n",
    "                [\"CC Output File\", f\"hypodd_cc_{node_i:03d}.reloc\"],\n",
    "                [\"CC File Size (bytes)\", str(cc_size)],\n",
    "                [\"CC Data Available\", \"Yes\" if cc_available else \"No\"],\n",
    "                [\"CT Status\", \"Completed Successfully\"],\n",
    "                [\"CC Status\", \"Completed Successfully\" if cc_available and cc_size > 50 else \"Skipped or Failed\"]\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(f\"{outputs_dir}/mlpipeline-ui-metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPODD RE-LOCATION PROCESSING COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CT catalog: {catalog_ct_path} ({ct_size} bytes)\")\n",
    "if catalog_cc_path:\n",
    "    print(f\"CC catalog: {catalog_cc_path} ({cc_size} bytes)\")\n",
    "print(f\"Output files saved to {outputs_dir}/ directory\")\n",
    "\n",
    "# Archive hypo_reloc directory\n",
    "import tarfile\n",
    "\n",
    "archive_path = \"hypo_reloc.tar.gz\"\n",
    "print(f\"\\nCreating archive: {archive_path}\")\n",
    "\n",
    "with tarfile.open(archive_path, \"w:gz\") as tar:\n",
    "    tar.add(outputs_dir, arcname=outputs_dir)\n",
    "\n",
    "# Verify archive creation\n",
    "if os.path.exists(archive_path):\n",
    "    archive_size = os.path.getsize(archive_path)\n",
    "    print(f\"Archive created successfully: {archive_path} ({archive_size} bytes)\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Failed to create archive: {archive_path}\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.969604,
   "end_time": "2025-06-03T02:33:27.556863",
   "environment_variables": {},
   "exception": null,
   "input_path": "Set_Config.ipynb",
   "output_path": "Set_Config-output.ipynb",
   "parameters": {},
   "start_time": "2025-06-03T02:33:26.587259",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
