{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abfd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypodd_ct(\n",
    "    node_i: int,\n",
    "    config_json: \"json\",\n",
    "    ct_file:str,\n",
    "    event: str,\n",
    "    station: str,\n",
    "    catalog_txt:str,\n",
    "    data_path: str ,\n",
    "):\n",
    "    import json\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "\n",
    "    with open(config_json, \"r\") as fp:\n",
    "        config = json.load(fp)\n",
    "    hypodd_path = os.path.join(data_path, \"hypodd\")\n",
    "\n",
    "    ct_inp = \"\"\"* RELOC.INP:\n",
    "*--- input file selection\n",
    "* cross correlation diff times:\n",
    "\n",
    "*\n",
    "*catalog P diff times:\n",
    "dt.ct\n",
    "*\n",
    "* event file:\n",
    "event.sel\n",
    "*\n",
    "* station file:\n",
    "stations.dat\n",
    "*\n",
    "*--- output file selection\n",
    "* original locations:\n",
    "hypodd.loc\n",
    "* relocations:\n",
    "hypodd.reloc\n",
    "* station information:\n",
    "hypodd.sta\n",
    "* residual information:\n",
    "hypodd.res\n",
    "* source paramater information:\n",
    "hypodd.src\n",
    "*\n",
    "*--- data type selection: \n",
    "* IDAT:  0 = synthetics; 1= cross corr; 2= catalog; 3= cross & cat \n",
    "* IPHA: 1= P; 2= S; 3= P&S\n",
    "* DIST:max dist [km] between cluster centroid and station \n",
    "* IDAT   IPHA   DIST\n",
    "    2     3     120\n",
    "*\n",
    "*--- event clustering:\n",
    "* OBSCC:    min # of obs/pair for crosstime data (0= no clustering)\n",
    "* OBSCT:    min # of obs/pair for network data (0= no clustering)\n",
    "* OBSCC  OBSCT    \n",
    "     0     8        \n",
    "*\n",
    "*--- solution control:\n",
    "* ISTART:  \t1 = from single source; 2 = from network sources\n",
    "* ISOLV:\t1 = SVD, 2=lsqr\n",
    "* NSET:      \tnumber of sets of iteration with specifications following\n",
    "*  ISTART  ISOLV  NSET\n",
    "    2        2      4\n",
    "*\n",
    "*--- data weighting and re-weighting: \n",
    "* NITER: \t\tlast iteration to used the following weights\n",
    "* WTCCP, WTCCS:\t\tweight cross P, S \n",
    "* WTCTP, WTCTS:\t\tweight catalog P, S \n",
    "* WRCC, WRCT:\t\tresidual threshold in sec for cross, catalog data \n",
    "* WDCC, WDCT:  \t\tmax dist [km] between cross, catalog linked pairs\n",
    "* DAMP:    \t\tdamping (for lsqr only) \n",
    "*       ---  CROSS DATA ----- ----CATALOG DATA ----\n",
    "* NITER WTCCP WTCCS WRCC WDCC WTCTP WTCTS WRCT WDCT DAMP\n",
    "   4     -9     -9   -9    -9   1     1      8   -9  70 \n",
    "   4     -9     -9   -9    -9   1     1      6    4  70 \n",
    "   4     -9     -9   -9    -9   1    0.8     4    2  70 \n",
    "   4     -9     -9   -9    -9   1    0.8     3    2  70 \n",
    "*\n",
    "*--- 1D model:\n",
    "* NLAY:\t\tnumber of model layers  \n",
    "* RATIO:\tvp/vs ratio \n",
    "* TOP:\t\tdepths of top of layer (km) \n",
    "* VEL: \t\tlayer velocities (km/s)\n",
    "* NLAY  RATIO \n",
    "   12     1.82\n",
    "* TOP \n",
    "0.0 1.0 3.0 5.0 7.0 9.0 11.0 13.0 17.0 21.0 31.00 31.10\n",
    "* VEL\n",
    "5.30 5.65 5.93 6.20 6.20 6.20 6.20 6.20 6.20 6.20 7.50 8.11\n",
    "*\n",
    "*--- event selection:\n",
    "* CID: \tcluster to be relocated (0 = all)\n",
    "* ID:\tcuspids of event to be relocated (8 per line)\n",
    "* CID    \n",
    "    0      \n",
    "* ID\n",
    "\"\"\"\n",
    "\n",
    "    with open(os.path.join(hypodd_path, \"ct.inp\"), \"w\") as fp:\n",
    "        fp.writelines(ct_inp)\n",
    "\n",
    "    def copy_file(fp_from, fp_to):\n",
    "        with open(fp_from, \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "        with open(fp_to, \"w\") as fp:\n",
    "            fp.writelines(lines)\n",
    "\n",
    "    copy_file(ct_file, os.path.join(hypodd_path, \"dt.ct\"))\n",
    "    copy_file(event, os.path.join(hypodd_path, \"event.sel\"))\n",
    "    copy_file(station, os.path.join(hypodd_path, \"stations.dat\"))\n",
    "\n",
    "    # os.system(f\"cat {ct_file}\")\n",
    "    # os.system(f\"cat {event}\")\n",
    "    # os.system(f\"cat {station}\")\n",
    "\n",
    "    HYPODD_CMD = f\"cd {hypodd_path} && /opt/hypodd/hypoDD ct.inp\"\n",
    "    print(HYPODD_CMD)\n",
    "    if os.system(HYPODD_CMD) != 0:\n",
    "        raise (\"{HYPODD_CMD}\" + \" failed!\")\n",
    "\n",
    "    copy_file(os.path.join(hypodd_path, \"hypodd.reloc\"), catalog_txt)\n",
    "\n",
    "    # try:\n",
    "    #     from minio import Minio\n",
    "\n",
    "    #     minioClient = Minio(s3_url, access_key=\"minio\", secret_key=\"minio123\", secure=secure)\n",
    "    #     minioClient.fput_object(\n",
    "    #         bucket_name,\n",
    "    #         f\"{config['region']}/hypodd/hypodd_ct_{node_i:03d}.reloc\",\n",
    "    #         catalog_txt,\n",
    "    #     )\n",
    "    # except Exception as err:\n",
    "    #     print(f\"ERROR: can not access minio service! \\n{err}\")\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('num_parallel.txt', 'r') as f:\n",
    "    nodes = [int(x) for x in f.read().strip('[]').split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hypodd_ct(\n",
    "    0,\n",
    "    config_json=\"config/config.json\",\n",
    "    ct_file=\"hypodd/dt.ct\",\n",
    "    event=\"hypodd/event.sel\",\n",
    "    station=\"hypodd/stations.dat\",\n",
    "    catalog_txt=\"hypodd_ct_catalog.txt\",\n",
    "    data_path=\"./\" ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f2fcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T02:33:27.435238Z",
     "iopub.status.busy": "2025-06-03T02:33:27.434883Z",
     "iopub.status.idle": "2025-06-03T02:33:27.438600Z",
     "shell.execute_reply": "2025-06-03T02:33:27.437997Z"
    },
    "papermill": {
     "duration": 0.006845,
     "end_time": "2025-06-03T02:33:27.439654",
     "exception": false,
     "start_time": "2025-06-03T02:33:27.432809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kubeflow Pipelines UI用のメタデータ出力\n",
    "if os.environ.get('ELYRA_RUNTIME_ENV') == 'kfp':\n",
    "    # For information about Elyra environment variables refer to\n",
    "    # https://elyra.readthedocs.io/en/stable/user_guide/best-practices-file-based-nodes.html#proprietary-environment-variables\n",
    "\n",
    "    metadata = {\n",
    "        'outputs': [\n",
    "            {\n",
    "                'storage': 'inline',\n",
    "                'source': f'# Run HypoDD re-location Complete\\n...',\n",
    "                'type': 'markdown',\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open('mlpipeline-ui-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.969604,
   "end_time": "2025-06-03T02:33:27.556863",
   "environment_variables": {},
   "exception": null,
   "input_path": "Set_Config.ipynb",
   "output_path": "Set_Config-output.ipynb",
   "parameters": {},
   "start_time": "2025-06-03T02:33:26.587259",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
